<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Creating an implementation of Learner | Deep Learning Lab</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Creating an implementation of Learner" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="A little rundown on an assignment from Deep Learning for Coders with fastai &amp; PyTorch" />
<meta property="og:description" content="A little rundown on an assignment from Deep Learning for Coders with fastai &amp; PyTorch" />
<link rel="canonical" href="https://cgfrac.github.io/deep-learning-lab/fastai/2020/11/30/implementing-learner.html" />
<meta property="og:url" content="https://cgfrac.github.io/deep-learning-lab/fastai/2020/11/30/implementing-learner.html" />
<meta property="og:site_name" content="Deep Learning Lab" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-11-30T00:00:00-06:00" />
<script type="application/ld+json">
{"description":"A little rundown on an assignment from Deep Learning for Coders with fastai &amp; PyTorch","url":"https://cgfrac.github.io/deep-learning-lab/fastai/2020/11/30/implementing-learner.html","@type":"BlogPosting","headline":"Creating an implementation of Learner","dateModified":"2020-11-30T00:00:00-06:00","datePublished":"2020-11-30T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://cgfrac.github.io/deep-learning-lab/fastai/2020/11/30/implementing-learner.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/deep-learning-lab/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://cgfrac.github.io/deep-learning-lab/feed.xml" title="Deep Learning Lab" /><link rel="shortcut icon" type="image/x-icon" href="/deep-learning-lab/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/deep-learning-lab/">Deep Learning Lab</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/deep-learning-lab/about/">About Me</a><a class="page-link" href="/deep-learning-lab/search/">Search</a><a class="page-link" href="/deep-learning-lab/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Creating an implementation of Learner</h1><p class="page-description">A little rundown on an assignment from Deep Learning for Coders with fastai & PyTorch</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-11-30T00:00:00-06:00" itemprop="datePublished">
        Nov 30, 2020
      </time>
       â€¢ <span class="read-time" title="Estimated read time">
    
    
      19 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/deep-learning-lab/categories/#fastai">fastai</a>
        
      
      </p>
    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-11-30-implementing-learner.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<blockquote><p><strong>Disclaimer:</strong> this post should be seen as a supplement to chapter 4 of <em>Deep Learning for Coders with fastai &amp; PyTorch</em>, by Jeremy Howard and Sylvain Gugger. A lot of code is lifted from there and I will mostly throw mental notes around. As such, it is highly recommended that you are familiar with the material before you read it. If you want to know more about the book or its companion course, you can visit this link: <a href="https://course.fast.ai/">https://course.fast.ai/</a>.
Having recently started reading the fantastic <em>Deep Learning for Coders with fastai &amp; PyTorch</em>, I was pretty impressed by the fourth chapter (<em>Under the hood: Training a Digit Classifier</em>) where we get to see the foundations of Deep Learning.</p>
</blockquote>
<p>I had to do a lot of back and forth to experiment and make sure I understood everything, but I think I got a good grasp of the concepts explored here, such as Stochastic Gradient Descent (or SGD).</p>
<p>At the end of the chapter, you are invited to implement your own <a href="https://docs.fast.ai/learner.html#Learner">Learner</a>. This is a class whose purpose is to handle the training loop with your data, model and loss function.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="An-interesting-experiment">An interesting experiment<a class="anchor-link" href="#An-interesting-experiment"> </a></h2><p>What I expected to be a simple exercise turned out to be a good review of this chapter's content. Because of this, I decided to discuss the implementation I came up with.</p>
<p>I relied on my intuition of how Learner would handle the training loop, <em>as it was explained in this chapter</em>, and mostly focused on making it work with the code that was exposed so far.</p>
<p>So it might be very different than how it's actually done, but this is the perfect excuse to go over the bits I found interesting.</p>
<blockquote><p><strong>Another disclaimer</strong>:expect a lot of the code to be pretty much a repeat of the book's content. Our focus today is the Learner, but I also wanted to keep a collection of personal notes for my own learning needs. Hopefully it is useful to you as well.</p>
</blockquote>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-first-get-our-data-ready">Let's first get our data ready<a class="anchor-link" href="#Let's-first-get-our-data-ready"> </a></h2><p>I decided to reuse the MNIST sample from this chapter, so I could directly compare my work with the book and focus on my Learner itself.</p>
<p>As a reminder, the MNIST sample contains digits 3 and 7, so our goal here is pretty simple: given 3 and 7 pictures, we must classify them correctly. We will quickly go over the points of interest, or rather my own mental notes to make sense of the datasets, as it is essentially a stripped down version of the work done in this chapter.</p>
<p>First we need to download the MNIST sample:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="n">untar_data</span><span class="p">(</span><span class="n">URLs</span><span class="o">.</span><span class="n">MNIST_SAMPLE</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Now we want paths to the respective training folders for 3 and 7. We will also use fastai's <code>ls</code> method on threes to get an idea of what the folder is like. Notice the number of items at the beginning of the ouput.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">threes</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="o">/</span><span class="s1">&#39;3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span><span class="o">.</span><span class="n">sorted</span><span class="p">()</span>
<span class="n">sevens</span> <span class="o">=</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;train&#39;</span><span class="o">/</span><span class="s1">&#39;7&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()</span><span class="o">.</span><span class="n">sorted</span><span class="p">()</span>
<span class="n">threes</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(#6131) [Path(&#39;/storage/data/mnist_sample/train/3/10.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10000.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10011.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10031.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10034.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10042.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10052.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/1007.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10074.png&#39;),Path(&#39;/storage/data/mnist_sample/train/3/10091.png&#39;)...]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We need to convert these images into something our computers can work with. That is, arrays where each cell corresponds to a pixel, expressed as a numerical value.</p>
<p>More precisely and for our needs, PyTorch's tensors are adequate. It will make it very convenient to make our calculations later, thanks to <strong>broadcasting</strong> in particular. Moreover, you might also remember that it is great for performance.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">three_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">threes</span><span class="p">]</span>
<span class="n">seven_tensors</span> <span class="o">=</span> <span class="p">[</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">sevens</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">three_tensors</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">seven_tensors</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(6131, 6265)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So far so good. As you can see, the length of <code>three_tensors</code> corresponds to the number of items we had in <code>three</code>.</p>
<p>Now let's use <code>torch.stack</code> to turn each list into a single <em>rank-3 tensor</em>. And let's convert our values to floats between 0 and 1 while we are at it.</p>
<p>Remember that our values range from 0 (black) to 255 (white), so simply dividing by 255 will do the trick. Notice how we directly divide the tensor. That's one of the magical things about broadcasting.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">stacked_threes</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">three_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">stacked_sevens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">seven_tensors</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">stacked_threes</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>torch.Size([6131, 28, 28])</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The shape confirms that our <code>stacked_threes</code> is a neat rank-3 tensor.</p>
<p>So that's our independent variables (or <em>xs</em>) nearly ready. Let's concatenate them into a single tensor, that we will convert the result to rank-2, where our pixels (28x28) are expressed into a single dimension.</p>
<p>The former is achieved with <code>torch.cat</code>, the latter with <code>view</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">stacked_threes</span><span class="p">,</span> <span class="n">stacked_sevens</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">train_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">threes</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="nb">len</span><span class="p">(</span><span class="n">sevens</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">train_x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">train_y</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([12396, 784]), torch.Size([12396, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We also made sure we had labels for our pictures with <code>train_y</code>. As you can see, our 3s will have a label of 1, and our 7s get 0. This will be handy for our <code>mnist_loss</code> method later.</p>
<p>The shapes are self-explanatory, but so we are 100% clear: 12396 is how many pictures we have in total (6131 + 6265), 784 is our 28x28 pixels per picture and 1 is our labels (that are single digits).</p>
<p>Next is having our <code>train_x</code> and <code>train_y</code> into a 2D list. We can easily achieve that with <code>zip</code>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span><span class="p">))</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">dset</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">dset</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([784]), tensor([1]), 12396)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Perfect! Now each picture is next to its appropriate label in a list of length 12396.</p>
<p>All that's left now is to feed our dataset to a <code>DataLoader</code>. This way we can iterate over the dataset by batches, which we will set to size 256.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">256</span><span class="p">)</span>
<span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="o">=</span> <span class="n">first</span><span class="p">(</span><span class="n">train_dl</span><span class="p">)</span>
<span class="n">xb</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">yb</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([256, 784]), torch.Size([256, 1]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At this point you might remember that our training dataset will not help much if we do not have a validation one as well. We need to calculate our accuracy and see how well we are doing after all.</p>
<p>Let's repeat the previous steps for our validation dataset as well, then.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_3_tens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;valid&#39;</span><span class="o">/</span><span class="s1">&#39;3&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()])</span>
<span class="n">valid_3_tens</span> <span class="o">=</span> <span class="n">valid_3_tens</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">valid_7_tens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">tensor</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">o</span><span class="p">))</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="p">(</span><span class="n">path</span><span class="o">/</span><span class="s1">&#39;valid&#39;</span><span class="o">/</span><span class="s1">&#39;7&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">ls</span><span class="p">()])</span>
<span class="n">valid_7_tens</span> <span class="o">=</span> <span class="n">valid_7_tens</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">valid_3_tens</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">valid_7_tens</span><span class="o">.</span><span class="n">shape</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can see how we have generated our rank-3 tensors with less lines of codes.</p>
<p>Withour further ado, let's get our <code>DataLoader</code> ready.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">valid_x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">valid_3_tens</span><span class="p">,</span> <span class="n">valid_7_tens</span><span class="p">])</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">)</span>
<span class="n">valid_y</span> <span class="o">=</span> <span class="n">tensor</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_3_tens</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_7_tens</span><span class="p">))</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">valid_dset</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">valid_x</span><span class="p">,</span> <span class="n">valid_y</span><span class="p">))</span>
<span class="n">valid_dl</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">valid_dset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">255</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We are all set. Let's finally bundle our <code>train_dl</code> and <code>valid_dl</code> into a <code>DataLoaders</code>.</p>
<p>This is what we will feed our Learner with at initialization.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">dls</span> <span class="o">=</span> <span class="n">DataLoaders</span><span class="p">(</span><span class="n">train_dl</span><span class="p">,</span> <span class="n">valid_dl</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-little-reminder-of-the-gradient-descent-process">A little reminder of the gradient descent process<a class="anchor-link" href="#A-little-reminder-of-the-gradient-descent-process"> </a></h2><p>Before we proceed, it will be helpful to remind ourselves of what the <em>gradient descent process</em> looks like. We do this now because the following steps won't come in order (at least until the training loop of our Learner itself is finally discussed).</p>
<p>If anything, writing this notebook made me realize how great Jeremy Howard and Sylvain Gugger were, at exposing the pieces in a way we could understand easily.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Make sure that you understand the process before moving forward. Revisit the course and book content if necessary!</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementing-our-loss-and-accuracy-functions">Implementing our loss and accuracy functions<a class="anchor-link" href="#Implementing-our-loss-and-accuracy-functions"> </a></h2><p>Before we implement our classes proper, we could get our loss and batch accuracy functions ready. They are going to be useful way later in our code, but they are short and help use make sense of some of the decisions we took when preparing our <code>DataLoaders</code>.</p>
<blockquote><p><strong>Tip:</strong> from this point onward, do not hesitate to do a bit of back and forth with later explanations. I will do my best to give pointers in case you are confused.</p>
<h3 id="The-loss-function">The loss function<a class="anchor-link" href="#The-loss-function"> </a></h3>
</blockquote>
<p>First, let's go over our loss function:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">mnist_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">targets</span><span class="p">):</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">targets</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="o">-</span><span class="n">predictions</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <em>loss function</em> is a critical piece of our training loop. This is where it sits in our <em>gradient descent</em> process:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="black" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00" fill="white">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>If you need to track down where it is called in our Learner class, check the <code>calc_grad</code> method. This is where the loss will be calculated after we got our predictions through our model.</p>
<p>Remember how our 3s were labeled as 1 and our 7s as 0 in <code>train_y</code>? This is where it comes in handy: if the target (our y) is a 3, then we will subtract the prediction from 1 to see how close we were to that number. Likewise, if our target is a 7, then our prediction alone will tell how close we were to 0.</p>
<p>Of note as well, is our use of the sigmoid function: to make the above calculation work as expected, we need to ensure our predictions are between 1 and 0.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_function</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="s1">&#39;Sigmoid&#39;</span><span class="p">,</span> <span class="nb">min</span><span class="o">=-</span><span class="mi">4</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You can also pay attention to the smooth curve we get here. That will make our gradients more useful, as you may remember.</p>
<h3 id="The-metrics-function">The metrics function<a class="anchor-link" href="#The-metrics-function"> </a></h3><p>While the loss function is useful to our training loop, we also need something that allows us to see how well our model is doing. This is where our metrics come in.</p>
<p>Since we are working on a classification problem, accuracy seems to be the metric of choice.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">batch_accuracy</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">xb</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">()</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="p">(</span><span class="n">preds</span><span class="o">&gt;</span><span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">yb</span>
    <span class="k">return</span> <span class="n">correct</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that as the name implies, we are going to calculate our accuracy over batches as we set them in our <code>train_dl</code> and <code>valid_dl</code>. Speaking of the latter, this is where our very important validation set comes into play.</p>
<p>As for the calculations themselves, we are again using <code>torch.sigmoid</code> for the same reasons as the loss function. While the actual accuracy will simply be the mean of our correct predictions (expressed as booleans).</p>
<p>Our Learner will rely on it in <code>validate_epoch</code>.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Optimizer-class">The Optimizer class<a class="anchor-link" href="#The-Optimizer-class"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MySGD</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">set_learning_rate</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
    
    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">data</span> <span class="o">-=</span> <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span>
            
    <span class="k">def</span> <span class="nf">zero_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">:</span>
            <span class="n">p</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>You might recognize the <code>BasicOptim</code> class from the part <em>Creating an Optimizer</em> in the chapter... Indeed this is simply the same class but going with my naming convention for today, and a minor <code>set_learning_rate</code> helper method, so that we feed our learning rate to the class only once.</p>
<p>So, we are now talking about this part in the gradient descent process:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="black" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So what is our <code>step</code> method doing exactly?</p>
<p>Remember what is the goal of our Stochastic Gradient Descent function: updating our parameters so that they lead to a lower loss. For this we are using our gradient to shortcut our way toward a smaller loss. The learning rate helps us modulate how big such a step will be.</p>
<p>Just as important for us here, is the <code>zero_grad</code> method. We need it or PyTorch will make our gradient calculations cumulatives. We do not want that! For each epoch, we want the gradients for our current loss so as to adjust as necessary.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-basic-neural-network-model">A basic neural network model<a class="anchor-link" href="#A-basic-neural-network-model"> </a></h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MySimpleNet</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">((</span><span class="n">size</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">((</span><span class="mi">30</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">init_params</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">std</span><span class="o">=</span><span class="mf">1.0</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">size</span><span class="p">)</span><span class="o">*</span><span class="n">std</span><span class="p">)</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span>
    
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xb</span><span class="p">):</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">xb</span><span class="nd">@self</span><span class="o">.</span><span class="n">w1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
        <span class="n">res</span> <span class="o">=</span> <span class="n">res</span><span class="nd">@self</span><span class="o">.</span><span class="n">w2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="k">return</span> <span class="n">res</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I hardcoded the dimensions to <code>size, 30</code> (where size would be 28x28 for our purposes today). I'm not sure if it is good practice, but probably fine for such a rudimentary model. I will keep that in mind when going deeper (no pun intended) into Deep Learning.</p>
<h3 id="Our-parameters">Our parameters<a class="anchor-link" href="#Our-parameters"> </a></h3><p><code>init_params</code> is of particular importance. This is actually our first step in the Gradient Descent process! Indeed, our weights and biases are the parameters that will be used in basically every step of the training loop.</p>
<p>For that effect, they will be randomly generated, and we will make sure that PyTorch keeps track of their gradients using <code>requires_grad</code>.</p>
<p>Accordingly, this is where we are in the process:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="black" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The <code>parameters</code> method will return all of our weights and biases together, for convenience.</p>
<h3 id="Neural-network">Neural network<a class="anchor-link" href="#Neural-network"> </a></h3><p>Lastly, and this is the fun part, we have a callable method that justifies the name for our class: this is our simple neural net, as it was explained to us by Jeremy Howard and Sylvain Gugger!</p>
<p>I was pretty surprised by how straightforward it is: two matrix multiplications in the form of the equation <code>batch @ weights + bias</code>, separated by a nonlinear function in the middle (this is the <em>rectified linear unit</em> or ReLU, whose calculation I decided to not abstract with the library, so that you can remind yourself how simple it actually is). This is our layers!</p>
<p>Two things to keep in mind here:</p>
<ol>
<li>It is necessary for us to have a nonlinear function to decouple both linear functions, least we would not benefit from having multiple layers.</li>
<li><p>Pay attention to the dimensions of our matrices as the calculations go. With our pictures that means we do:</p>
<ul>
<li>[256x784] x [784x30] + [30] = [256x30] matrix</li>
<li>Our ReLU function to turn all negative values to 0 in the resulting matrix</li>
<li>[256x30] x [30x1] + [1] = [256x1] vector</li>
</ul>
<p>Where 256 is the size of our batch and 784 is our 28x28 pixels.</p>
</li>
</ol>
<p>If you are not sure of what the last part means, I recommend you to review matrix multiplications (there is a wonderful explanation on page 165). <em>Broadcasting</em> is also at play here.</p>
<p>Anyway, this magical piece of code is taking care of this part of our process:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="black" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>I'm not entirely sure on why we bundle the parameters together with the model, but my intuition is that by doing so we ensure that our matrices are properly sized for the necessary matrix multiplications.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Learner-class">The Learner class<a class="anchor-link" href="#The-Learner-class"> </a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, the reason we have been writing this piece!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">MyLearner</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">opt_func</span><span class="p">,</span> <span class="n">loss_func</span><span class="p">,</span> <span class="n">metrics</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_dl</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_dl</span> <span class="o">=</span> <span class="n">dls</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_func</span> <span class="o">=</span> <span class="n">opt_func</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span> <span class="o">=</span> <span class="n">loss_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metrics</span> <span class="o">=</span> <span class="n">metrics</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span> <span class="o">=</span> <span class="p">{}</span>
        
    <span class="k">def</span> <span class="nf">calc_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">):</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss_func</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">xb</span><span class="p">,</span> <span class="n">yb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_dl</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">calc_grad</span><span class="p">(</span><span class="n">xb</span><span class="p">,</span> <span class="n">yb</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_func</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">opt_func</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">validate_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">accs</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">metrics</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">xb</span><span class="p">),</span> <span class="n">yb</span><span class="p">)</span> <span class="k">for</span> <span class="n">xb</span><span class="p">,</span><span class="n">yb</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">valid_dl</span><span class="p">]</span>
        <span class="k">return</span> <span class="nb">round</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">accs</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="mi">4</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epochs</span><span class="p">,</span> <span class="n">lr</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">opt_func</span><span class="o">.</span><span class="n">set_learning_rate</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">()</span>
            <span class="n">mean_accuracy</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validate_epoch</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">recorder</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_accuracy</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">mean_accuracy</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39; &#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see, there is a lot going on. However, at the same time, it is still very close to the logic exposed by this chapter.</p>
<p>Let's take a look in order of execution.</p>
<h3 id="init">init<a class="anchor-link" href="#init"> </a></h3><p>I just went with what the instantiation looked like, which meant providing the <code>DataLoaders</code>, then giving a model (this is our simple neural network), the optimization function (our SGD), the loss function (<code>mnist_loss</code> earlier) and finally our metrics (<code>batch_accuracy</code>).</p>
<p>Our <code>DataLoaders</code> is separated back to our training and validation <code>DataLoader</code>. It was convenient for my immediate needs but maybe there is a saner way to go about it, in a more complex implementation of <code>Learner</code>.</p>
<p>I made a bare bone <code>recorder</code> in the form of a dictionary as well. It's clearly not what the recorder actually is in fastai, but all I wanted was a quick and dirty way to plot our metrics later.</p>
<p>With that explanation being out of the way, let's just initialize our Learner object now:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">learn</span> <span class="o">=</span> <span class="n">MyLearner</span><span class="p">(</span><span class="n">dls</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">MySimpleNet</span><span class="p">(</span><span class="mi">28</span><span class="o">*</span><span class="mi">28</span><span class="p">),</span> <span class="n">opt_func</span><span class="o">=</span><span class="n">MySGD</span><span class="p">,</span> <span class="n">loss_func</span><span class="o">=</span><span class="n">mnist_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="n">batch_accuracy</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Note that we initialize our model there. Thus fulfilling the first step of this graph:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="black" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="The-training-loop">The training loop<a class="anchor-link" href="#The-training-loop"> </a></h3><p>Now we can focus on the training loop itself, whose handling is the purpose of our Learner class.</p>
<h4 id="fit">fit<a class="anchor-link" href="#fit"> </a></h4><p>It all begins with our <code>fit</code> method, where we give the number of epochs we will go through. This is also where the <em>learning rate</em> is set for the optimization function (again, the SGD we initialize the Learner with).</p>
<p>At the beginning of each iteration, we use <code>train_epoch</code> which we will cover now.</p>
<h4 id="train_epoch">train_epoch<a class="anchor-link" href="#train_epoch"> </a></h4><p>From there, we are going to loop through all the batches of our <code>train_dl</code>, separated into our xs (remember: our pictures) and ys (the labels)</p>
<p>First in our loop, <code>calc_grad</code> is called.</p>
<h4 id="calc_grad">calc_grad<a class="anchor-link" href="#calc_grad"> </a></h4><p>You may have realized, but we are finally mentioning a critical piece of the Gradient Descent process. That is:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="black" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00" fill="white">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But in reality, since the method is first calculating the predictions using our neural network, and the loss using <code>mnist_loss</code> with said predictions and this batch's ys, this method is essentially taking care of much more:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="black" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="black" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00" fill="white">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="black" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00" fill="white">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>The gradient itself is calculated using <code>backward</code>. Remember when we used <code>requires_grad</code> during parameters initialization? This was in preparation for this moment: the <em>backward propagation</em>!</p>
<p>Since PyTorch kept in mind our parameters, from our loss it will be able to work its way back to the predictions, then the parameters, to distribute the gradients.</p>
<p>From there we are done with the current batch and can go back to <code>train_epoch</code>.</p>
<h4 id="back-to-train_epoch">back to train_epoch<a class="anchor-link" href="#back-to-train_epoch"> </a></h4><p>Now that we have calculated the gradients, we need to update the parameters using our optimization function.</p>
<p>This is done using <code>step</code> in our SGD class, thus:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="black" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="none" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>After that, we make sure to reset the gradients with <code>zero_grad</code>, for the reasons explained earlier in the SGD part.</p>
<h4 id="back-to-fit">back to fit<a class="anchor-link" href="#back-to-fit"> </a></h4><p>Now that we trained our epoch, we can use <code>validate_epoch</code> to get the accuracy of this iteration. The code is self-explanatory, but notice that this is where <code>batch_accuracy</code> is finally useful.</p>
<p>We also put the resulting mean accuracy in our <code>recorder</code> for later.</p>
<p>And this is pretty much all there is to our training loop. After we repeated the above process for the number of epochs we set, we finally reach this point:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
&lt;!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd"&gt;
<!-- Generated by graphviz version 2.42.3 (20191010.1750)
 -->
<!-- Title: G Pages: 1 -->
<svg width="661pt" height="78pt" viewBox="0.00 0.00 660.87 78.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 74)">
<title>G</title>
<polygon fill="white" stroke="transparent" points="-4,4 -4,-74 656.87,-74 656.87,4 -4,4" />
<!-- init -->
<g id="node1" class="node">
<title>init</title>
<ellipse fill="none" stroke="black" cx="27" cy="-18" rx="27" ry="18" />
<text text-anchor="middle" x="27" y="-14.3" font-family="Times,serif" font-size="14.00">init</text>
</g>
<!-- predict -->
<g id="node2" class="node">
<title>predict</title>
<ellipse fill="none" stroke="black" cx="135.2" cy="-18" rx="44.39" ry="18" />
<text text-anchor="middle" x="135.2" y="-14.3" font-family="Times,serif" font-size="14.00">predict</text>
</g>
<!-- init&#45;&gt;predict -->
<g id="edge1" class="edge">
<title>init&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M54.25,-18C62.37,-18 71.63,-18 80.89,-18" />
<polygon fill="black" stroke="black" points="80.89,-21.5 90.89,-18 80.89,-14.5 80.89,-21.5" />
</g>
<!-- loss -->
<g id="node3" class="node">
<title>loss</title>
<ellipse fill="none" stroke="black" cx="244.99" cy="-52" rx="28.7" ry="18" />
<text text-anchor="middle" x="244.99" y="-48.3" font-family="Times,serif" font-size="14.00">loss</text>
</g>
<!-- predict&#45;&gt;loss -->
<g id="edge2" class="edge">
<title>predict&#45;&gt;loss</title>
<path fill="none" stroke="black" d="M170.6,-28.85C183.05,-32.78 197.09,-37.21 209.54,-41.14" />
<polygon fill="black" stroke="black" points="208.53,-44.49 219.12,-44.16 210.64,-37.81 208.53,-44.49" />
</g>
<!-- gradient -->
<g id="node4" class="node">
<title>gradient</title>
<ellipse fill="none" stroke="black" cx="406.63" cy="-52" rx="50.09" ry="18" />
<text text-anchor="middle" x="406.63" y="-48.3" font-family="Times,serif" font-size="14.00">gradient</text>
</g>
<!-- loss&#45;&gt;gradient -->
<g id="edge3" class="edge">
<title>loss&#45;&gt;gradient</title>
<path fill="none" stroke="black" d="M273.8,-52C293.82,-52 321.57,-52 346.45,-52" />
<polygon fill="black" stroke="black" points="346.55,-55.5 356.55,-52 346.55,-48.5 346.55,-55.5" />
</g>
<!-- step -->
<g id="node5" class="node">
<title>step</title>
<ellipse fill="none" stroke="black" cx="524.23" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="524.23" y="-14.3" font-family="Times,serif" font-size="14.00">step</text>
</g>
<!-- gradient&#45;&gt;step -->
<g id="edge4" class="edge">
<title>gradient&#45;&gt;step</title>
<path fill="none" stroke="black" d="M445.8,-40.77C459.01,-36.89 473.76,-32.55 486.82,-28.71" />
<polygon fill="black" stroke="black" points="487.82,-32.06 496.43,-25.88 485.85,-25.35 487.82,-32.06" />
</g>
<!-- step&#45;&gt;predict -->
<g id="edge6" class="edge">
<title>step&#45;&gt;predict</title>
<path fill="none" stroke="black" d="M493.68,-18C428.65,-18 272.39,-18 189.67,-18" />
<polygon fill="black" stroke="black" points="189.47,-14.5 179.47,-18 189.47,-21.5 189.47,-14.5" />
<text text-anchor="middle" x="315.09" y="-21.8" font-family="Times,serif" font-size="14.00">repeat</text>
</g>
<!-- stop -->
<g id="node6" class="node">
<title>stop</title>
<ellipse fill="black" stroke="black" cx="622.32" cy="-18" rx="30.59" ry="18" />
<text text-anchor="middle" x="622.32" y="-14.3" font-family="Times,serif" font-size="14.00" fill="white">stop</text>
</g>
<!-- step&#45;&gt;stop -->
<g id="edge5" class="edge">
<title>step&#45;&gt;stop</title>
<path fill="none" stroke="black" d="M554.84,-18C563.24,-18 572.53,-18 581.44,-18" />
<polygon fill="black" stroke="black" points="581.64,-21.5 591.64,-18 581.64,-14.5 581.64,-21.5" />
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Let's-test-our-Learner">Let's test our Learner<a class="anchor-link" href="#Let's-test-our-Learner"> </a></h2><p>There is only one thing left to do: have our learning rate ready and launch <code>fit</code> to see how well our Learner is doing!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">lr</span> <span class="o">=</span> <span class="o">.</span><span class="mi">1</span>
<span class="n">learn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.7794 0.85 0.8804 0.9044 0.9147 0.923 0.9304 0.9333 0.9343 0.9353 0.9367 0.9407 0.9436 0.9465 0.9475 0.9495 0.95 0.95 0.9509 0.9509 0.9514 0.9524 0.9524 0.9529 0.9539 0.9539 0.9539 0.9544 0.9544 0.9544 0.9554 0.9563 0.9568 0.9568 0.9568 0.9568 0.9578 0.9578 0.9578 0.9583 </pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's a lot of numbers. As we have been taught in the book, we could instead plot the accuracy for our epochs.</p>
<p>Our dirty simple <code>recorder</code> will show its usefulness:</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">keys</span><span class="p">(),</span> <span class="n">learn</span><span class="o">.</span><span class="n">recorder</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[&lt;matplotlib.lines.Line2D at 0x7f65d8d82250&gt;]</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Wrap-up">Wrap-up<a class="anchor-link" href="#Wrap-up"> </a></h2><p>Playing with the learning rate might yield better results, But the goal today was to have a working Learner and review a few parts of chapter 4, so I'll call it a success.</p>
<p>I'm pretty excited about reading on the learning rate finder.</p>
<p>Something I mostly (not to say completely!) glossed over is the reasoning behind using gradients for weight adjustment. If you are still unclear on this aspect, I recommend to reread the relevant parts in the book as they provide a fantastic intuition. Khan Academy is also replete with calculus lessons and exercises if you want to dive deeper in this subject.</p>
<p>The big picture here is that gradients are making parameter adjustments faster.</p>
<h2 id="What's-next?">What's next?<a class="anchor-link" href="#What's-next?"> </a></h2><p>There is another, more exciting and potentially much more difficult task ahead: using the principles learned so far to work on the whole MNIST dataset.</p>
<p>I may use the built-in fastai features to do this work, but I expect things to be very instructive. Today's work was mostly seeing how the pieces fit together. This next project will be about providing useful work.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="CGfrac/deep-learning-lab"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/deep-learning-lab/fastai/2020/11/30/implementing-learner.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/deep-learning-lab/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/deep-learning-lab/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/deep-learning-lab/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Personal notes in a data science learning journey.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/fastai" title="fastai"><svg class="svg-icon grey"><use xlink:href="/deep-learning-lab/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/deep-learning-lab/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
